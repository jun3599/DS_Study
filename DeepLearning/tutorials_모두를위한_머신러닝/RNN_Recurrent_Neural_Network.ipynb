{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f01783",
   "metadata": {},
   "source": [
    "# RNN (Recurent Neural Network)\n",
    "* 해당 학습은 [김성원교수의 모두를 위한 머신러닝/딥러닝 강의](https://hunkim.github.io/ml/)와 [텐서플로우로 시작하는 딥러닝 기초](https://www.boostcourse.org/ai212/joinLectures/25072) 의 강의를 통해 진행하였습니다. \n",
    "* 순환신경망 ( venila RNN / LSTM / GRU )에 대한 자세한 이론적 학습은 이전에 주가예측을 위한 모형 고안을 하던 당시 학습한 기록이 남아 있습니다. \n",
    "[RNN study](https://github.com/jun3599/Stock_Market_prediction/blob/main/recurent_neural_network.ipynb)\n",
    "* 이번 강좌에서는 보다 Low Level API를 이용하여 모형을 구현하고, 순환신경망에 대한 심층적인 이해와 복습을 목적으로 학습을 진행합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24e3e7b",
   "metadata": {},
   "source": [
    "# 순환신경망의 기본적 개념 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e728fa",
   "metadata": {},
   "source": [
    "## Idea of RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca50446",
   "metadata": {},
   "source": [
    "* 기존의 신경망들은, 입력과 출력의 구조가 일방향적인 학습이 이루어지는 구조였습니다. ![cf.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FMe6NZ%2FbtqAkybHfbJ%2Ffx5NKmeXgq8nR5XkiStpFK%2Fimg.png) 따라서, '동그라미'로 표현되는 하나의 셀은 구체적으로 이전 layer에서 입력된 값들에 각자의 고유 가중치를 내적하여 다음 layer의 각 cell들에게 일방적으로 전달하는 구조를 가지고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd097e",
   "metadata": {},
   "source": [
    "![net_with_rnn.png](https://gblobscdn.gitbook.com/assets%2F-LvBP1svpACTB1R1x_U4%2F-LwEQnQw8wHRB6_2zYtG%2F-LwEZT8zd07mLDuaQZwy%2Fimage.png?alt=media&token=93a3c3e2-e32b-4fec-baf5-5e6b092920c4) \n",
    "* 반면, RNN 계열의 신경망의 전체 모습은, 위에서 보이는 바와 같이 하나의 cell에서 일어나는 연산이 다소 복잡한 구조로 이루어져 있습니다. \n",
    "* 즉, 하나의 Cell은 자신의 이전 출력값을 새로운 입력과 함께 입력받으며 출력값을 계산합니다. \n",
    "* 즉, 현재의 값을 계산하기 위해 이전까지의 결과를 함께 고려하는 구조의 신경망입니다. \n",
    "* 이러한 특성 덕택에, RNN Cell을 이용한 순환신경망은 순서를 갖는 Sequence data를 효율적으로 처리 가능하다는 특성을 지닙니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d70ec",
   "metadata": {},
   "source": [
    "## RNN의 구조 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb18635",
   "metadata": {},
   "source": [
    "##### Venila RNN의  Cell 구조 \n",
    "![venilaRNNCell.png](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile23.uf.tistory.com%2Fimage%2F2578204757AC186F2A70DC)\n",
    "* 위의 그림은 하나의 RNN Cell의 구조를 보여줍니다. 그림의 왼쪽을 이해의 편리함을 위해 오른쪽 그림처럼 펼져 이해해 보겠습니다. \n",
    "\n",
    "* 그림과 같이 RNN 계열의 신경망은 은닉층의 노드에서 활성화 함수를 통해 나온 결과값을 출력층 방향으로도 보내면서, 다시 은닉층 노드의 다음 계산의 입력으로 보내는 특징을 갖고있습니다.  \n",
    "\n",
    "* 은닉층의 각 메모리셀은 각각의 시점에서 바로 이전시점에서의 은닉층의 메모리 셀에서 나온 값을 자신의 입력으로 사용하는 재귀적 활동을 수행함\n",
    "\n",
    "* 메모리 셀이 출력층 방향으로 또는 다음 시점 t+1의 자신에게 보내는 값을 은닉 상태(hidden state) 라고 합니다. 다시 말해 t 시점의 메모리 셀은 t-1 시점의 메모리 셀이 보낸 은닉 상태값을 t 시점의 은닉 상태 계산을 위한 입력값으로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac74ab9c",
   "metadata": {},
   "source": [
    "##### RNN Cell 의 계산 절차 details \n",
    "\n",
    "![rnnCal.png](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/12/06022525/bptt.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f4254",
   "metadata": {},
   "source": [
    "* 하나의 RNN Cell은 위와 같은 방식의 계산을 진행합니다. \n",
    "    - RNN Cell은 새로운 입력을 받는 부분과, 이전의 과정에서 도출된 값을 받는 부분으로 이루어져 있습니다. \n",
    "    - 각각의 과정에서는 새로운 입력에 대한 가중치 W_xh와 이전의 값의 입력에 대한 가중치인 W_hh를 이용하여 값을 계산하고, 최종적으로 활성함수(주로 tanh)를 적용하여 다음층으로 값을 넘겨주는것과 동시에, W_yh를 곱한 값을 출력층으로 전달합니다.   \n",
    "    \n",
    "    $$h_t = f_w(h_{t-1}, x_t)$$  \n",
    "    \n",
    "    $$h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t)$$  \n",
    "    $$y_t = W_{hy}h_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27414f5b",
   "metadata": {},
   "source": [
    "##### 계산 예시 \n",
    "![examRnn.png](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile23.uf.tistory.com%2Fimage%2F243AD34957ADEEE633DE7B) \n",
    "* 위의 계산 과정은 Hello 라는 하나의 단어를 sequence 형태로 변환후, 이를 개별적인 원핫백터로서 입력하여 Hell 다음에 오는 데이텀을 예측하는 모형의 예시입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62703508",
   "metadata": {},
   "source": [
    "## +𝛼 : Tensor의 차원 이해하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462ade7",
   "metadata": {},
   "source": [
    "![tensor.png](https://res.cloudinary.com/practicaldev/image/fetch/s--VaxrSdrA--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/bp6ux6ppf5t5amwkxklq.jpg)\n",
    "\n",
    "* 텐서는 기본적으로 어떠한 집합을 원소로 갖는 구조를 의미합니다. \n",
    "    - 예를 들어, rank가 2인 행렬을 원소로 갖는 텐서를 3D 텐서라고 합니다. \n",
    "    - 또한 이러한 3D tensor를 원소로 갖는 텐서를 4D 텐서라고 합니다. \n",
    "    - 즉, 자신의 원소로써, 자신보다 낮은 차원의 원소를 포함하는 구조를 N-D tensor라고 부릅니다. \n",
    "* 텐서의 일반적인 차원에 대한 표기 방식은, 가장 낮은 차원의 구성 갯수를 왼쪽에서 시작해, 오른쪽에는 가장 큰 차원이 갖는 원소의 수를 적습니다. \n",
    "    - 예를들어, \n",
    "    $$\\matrix{[[[1, 2, 3, 4],[5, 6, 7, 8],[9, 10, 11, 12]],\\\\\n",
    "    [[1, 2, 3, 4],[5, 6, 7, 8],[9, 10, 11, 12]]]}$$  \n",
    "    \n",
    "    위의 수식은 두개의 행렬을 원소로 갖는 3D tensor 구조를 보여줍니다. 이때 각 행렬은 3개의 벡터를 포함하고 있으며, 각각의 벡터는 4개의 차원을 갖습니다. \n",
    "    * 이를 텐서의 차원으로 표기하면 Tensor(2,3,4)로 표기할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7102e",
   "metadata": {},
   "source": [
    "# Basic of RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cbbfd",
   "metadata": {},
   "source": [
    "## Basic of RNN1. 하나의 벡터 입력 받기\n",
    "* 가장 간단한 RNN모형의 구현을 통해 모형의 기초 사항에 대해 살펴봅니다.\n",
    "* 구현할 모형에 대한 상세사항은 다음과 같습니다. \n",
    "![basicRNNexam.png](https://camo.githubusercontent.com/db4a71ef36402dca5f6d3787bf4035a4eb1c4839/68747470733a2f2f636c6f75642e67697468756275736572636f6e74656e742e636f6d2f6173736574732f3930313937352f32333334383732372f63633938313835362d666365372d313165362d383365612d3462313837343733343636622e706e67)  \n",
    "    - 모형의 목적 : 한가지 단어의 스펠링을 문자단위로 입력받아, 다음 문자를 예측하는 모형을 구현합니다. \n",
    "    - 모형의 형태 : 하나의 vienila Rnn Cell로 이루어진 모형을 이용합니다. \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e87ed",
   "metadata": {},
   "source": [
    "### 필요 라이브러리 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff81f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "\n",
    "# 우리가 사용할 simpleRNNCell, RNN, SimpleRNN을 담고 있습니다. \n",
    "from tensorflow.keras import layers \n",
    "\n",
    "# 모형 생성기 \n",
    "from tensorflow.keras import Sequential, Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d0536",
   "metadata": {},
   "source": [
    "### 학습용 데이터 준비하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6ea547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원한 벡터 형태로 각 글자를 표현합니다. \n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f64741",
   "metadata": {},
   "source": [
    "### 모형 구현 \n",
    "* 모형을 구현하는 방식에는 크게 두가지 방식이 있습니다. \n",
    "    - 방식1. : Cell을 별도로 생성하고 이를 RNN 전용 드라이버에 인자로 넘겨주는 방식  \n",
    "    - 방식2. : Cell을 별도로 생성하지 않고, 즉각적으로 모형 생성하기   \n",
    "( 방식1과 같은 방법을 사용하는 이유는 모형을 유동적으로 변경하고, 다룰수 있다는 장점에 있습니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f66f8",
   "metadata": {},
   "source": [
    "#### 방식1. \n",
    "* layers.SimpleRNNCell을 활용하여 하나의 셀을 만든 후, \n",
    "* layers.RNN에 해당 셀을 전달함으로써 모형을 구성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a38c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [[[1. 0. 0. 0.]]], shape : (1, 1, 4)\n",
      "outputs: [[[ 0.05821195 -0.42081955]]], shape: (1, 1, 2)\n",
      "states: [[ 0.05821195 -0.42081955]], shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# 하나의 RNN Cell을 생성합니다. \n",
    "# 모형을 (input dim = 4 --> output dim = 2 ) 구조로 생성합니다. \n",
    "\n",
    "# 데이터의 형태 정의 \n",
    "x_data = np.array([[h]], dtype=np.float32)\n",
    "# [[h]] == [[[1,0,0,0]]]  --> shape (1, 1, 4)\n",
    "\n",
    "# 셀과 셀 컴파일러 정의 \n",
    "hidden_size = 2  # 우리가 원하는 출력의 차원, 즉 출력 유닛수 \n",
    "cell = layers.SimpleRNNCell(units=hidden_size) # unit옵션은 출력 신호의 수를 지정 \n",
    "rnn = layers.RNN(cell= cell, return_sequences=True, return_state=True)\n",
    "# 데이터의 입력 및 값 계산 \n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "# 결과의 출력 \n",
    "print('x_data: {}, shape : {}'.format(x_data, x_data.shape))\n",
    "print('outputs: {}, shape: {}'.format(outputs, outputs.shape))\n",
    "print('states: {}, shape: {}'.format(states, states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8d296",
   "metadata": {},
   "source": [
    "[딥러닝을 이용한 자연어처리 입문](https://wikidocs.net/106473)\n",
    "* return_sequences=True를 선택하면 메모리 셀이 모든 시점(time step)에 대해서 은닉 상태값을 출력하며, 별도 기재하지 않거나 return_sequences=False로 선택할 경우에는 메모리 셀은 하나의 은닉 상태값만을 출력합니다. 그리고 이 하나의 값은 마지막 시점(time step)의 메모리 셀의 은닉 상태값입니다.\n",
    "\n",
    "* return_state가 True일 경우에는 return_sequences의 True/False 여부와 상관없이 마지막 시점의 은닉 상태를 출력합니다. 가령, return_sequences가 True이면서, return_state를 True로 할 경우 SimpleRNN은 두 개의 출력을 리턴합니다.첫번째 출력은 return_sequences=True로 인한 출력으로 모든 시점의 은닉 상태입니다. 두번째 출력은 return_state=True로 인한 출력으로 마지막 시점의 은닉 상태입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d2ea9b",
   "metadata": {},
   "source": [
    "##### 결과의 해석 \n",
    "* 위의 학습 결과에서, outputs와 states에는 같은 값이 들어가 있지만, 차원이 다른 모습을 보여줍니다. \n",
    "    - 이는, outputs의 경우 모든 sequence의 결과값을 담고 있음을 말하고, states에는 마지막 hiddenstate의 결과만을 담고 있음을 알 수 있습니다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f43adec",
   "metadata": {},
   "source": [
    "#### 방식2: 한줄의 코드로 만들기 \n",
    "* 위의 방식과 같은 결과를 만들어냅니다. \n",
    "* 하지만, 이의 경우 모형의 셀을 유동적으로 변경할 수 없다는 단점을 지닙니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf6c977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [[[1. 0. 0. 0.]]], shape: (1, 1, 4)\n",
      "outputs: [[[ 0.26618353 -0.37249312]]], shape: (1, 1, 2)\n",
      "states: [[ 0.26618353 -0.37249312]], shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[h]],dtype=np.float32)\n",
    "\n",
    "# 보다 high level API로 한줄로 간편하게 생성이 가능합니다. \n",
    "rnn = layers.SimpleRNN(units=hidden_size, return_sequences=True, return_state=True)\n",
    "\n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print('x_data: {}, shape: {}'.format(x_data, x_data.shape))\n",
    "print('outputs: {}, shape: {}'.format(outputs, outputs.shape))\n",
    "print('states: {}, shape: {}'.format(states, states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1414cff",
   "metadata": {},
   "source": [
    "## Basic of RNN2: 시퀀스 형태의 입력 받기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d42ad",
   "metadata": {},
   "source": [
    "##### Unfolding to n Sequence \n",
    "![basicRNNexam2.png](https://camo.githubusercontent.com/194a1b757f5f0c000f1b1a83a1747da3f8489b48/68747470733a2f2f636c6f75642e67697468756275736572636f6e74656e742e636f6d2f6173736574732f3930313937352f32333338333633342f36343965666430612d666438322d313165362d393235642d3830343132343237343362302e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec16a3c9",
   "metadata": {},
   "source": [
    "* 이번에는 4개의 차원으로 이루어진 Vector 5개를 원소로 갖는 1개의 Metrix를 입력으로 제공하겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94903fa",
   "metadata": {},
   "source": [
    "##### 데이터 형태 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74ee247",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[h, e, l, l, o]], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451bbee",
   "metadata": {},
   "source": [
    "### 방식 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1034bf",
   "metadata": {},
   "source": [
    "##### 셀 생성 및 초기화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64d516a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 2 \n",
    "cell = layers.SimpleRNNCell(units=hidden_size)\n",
    "rnn = layers.RNN(cell=cell, return_sequences=True, return_state= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7160c",
   "metadata": {},
   "source": [
    "##### 학습 및 결과 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae23607",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, states = rnn(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc7097c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]], shape: (1, 5, 4) \n",
      "\n",
      "outputs: [[[ 0.5424151  -0.5437594 ]\n",
      "  [-0.7516673   0.855709  ]\n",
      "  [ 0.29133034 -0.7488676 ]\n",
      "  [-0.9129436  -0.43150187]\n",
      "  [-0.40806997 -0.58041596]]], shape: (1, 5, 2) \n",
      "\n",
      "states: [[-0.40806997 -0.58041596]], shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print('x_data: {}, shape: {} \\n'.format(x_data, x_data.shape))\n",
    "print('outputs: {}, shape: {} \\n'.format(outputs, outputs.shape))\n",
    "print('states: {}, shape: {}'.format(states, states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b84b9",
   "metadata": {},
   "source": [
    "### 방식2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8091a1",
   "metadata": {},
   "source": [
    "###### 셀 생성 및 초기화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2bcf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 2 \n",
    "\n",
    "rnn = layers.SimpleRNN(units=hidden_size, return_sequences= True, return_state= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c5bfb",
   "metadata": {},
   "source": [
    "##### 학습 및  결과 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebaeb9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, states = rnn(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ae8358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]], shape: (1, 5, 4) \n",
      "\n",
      "outputs: [[[-0.7172524   0.711289  ]\n",
      "  [ 0.64156586  0.85676116]\n",
      "  [ 0.43649918 -0.90608877]\n",
      "  [-0.8634083  -0.911343  ]\n",
      "  [-0.8824211   0.9260854 ]]], shape: (1, 5, 2) \n",
      "\n",
      "states: [[-0.8824211  0.9260854]], shape: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print('x_data: {}, shape: {} \\n'.format(x_data, x_data.shape))\n",
    "print('outputs: {}, shape: {} \\n'.format(outputs, outputs.shape))\n",
    "print('states: {}, shape: {}'.format(states, states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b964b",
   "metadata": {},
   "source": [
    "## Basic of RNN: Batching input "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bfe018",
   "metadata": {},
   "source": [
    "![basicRNNexam3.png](https://camo.githubusercontent.com/36e4d1308f70201943dd019c5b5f7b3569f1f5bb/68747470733a2f2f636c6f75642e67697468756275736572636f6e74656e742e636f6d2f6173736574732f3930313937352f32333338333638312f39393433613966632d666438322d313165362d383132312d6264313837393934653234392e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b53be",
   "metadata": {},
   "source": [
    "* 이번에는 4개의 글자로 구성된 3개의 단어를 원소로 갖는 하나의 3d tensor를 입력으로 제공해 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98175b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [[[1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]]], shape: (3, 5, 4) \n",
      "\n",
      "outputs: [[[ 0.587694    0.27291715]\n",
      "  [ 0.0587311   0.73999214]\n",
      "  [ 0.02868586  0.30735892]\n",
      "  [ 0.3823171   0.09790175]\n",
      "  [ 0.21077834  0.81382513]]\n",
      "\n",
      " [[ 0.04168834  0.29379526]\n",
      "  [-0.1125332   0.7260708 ]\n",
      "  [-0.03502973  0.1567525 ]\n",
      "  [ 0.46939644 -0.02585174]\n",
      "  [ 0.71496844  0.33160612]]\n",
      "\n",
      " [[ 0.58185506 -0.06414629]\n",
      "  [ 0.75376153  0.40390375]\n",
      "  [ 0.01538492  0.8202128 ]\n",
      "  [-0.59539676  0.59246236]\n",
      "  [-0.12951216 -0.32195243]]], shape: (3, 5, 2) \n",
      "\n",
      "states: [[ 0.21077834  0.81382513]\n",
      " [ 0.71496844  0.33160612]\n",
      " [-0.12951216 -0.32195243]], shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# One cell RNN input_dim (4) -> output_dim (2). sequence: 5, batch 3\n",
    "# 3 batches 'hello', 'eolll', 'lleel'\n",
    "x_data = np.array([[h, e, l, l, o],\n",
    "                   [e, o, l, l, l],\n",
    "                   [l, l, e, e, l]], dtype=np.float32)\n",
    "\n",
    "hidden_size = 2\n",
    "rnn = layers.SimpleRNN(units=2, return_sequences=True, return_state=True)    \n",
    "outputs, states = rnn(x_data)\n",
    "\n",
    "print('x_data: {}, shape: {} \\n'.format(x_data, x_data.shape))\n",
    "print('outputs: {}, shape: {} \\n'.format(outputs, outputs.shape))\n",
    "print('states: {}, shape: {}'.format(states, states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7a2a0",
   "metadata": {},
   "source": [
    "## Basic of RNN : Many to One - Sentiment classification \n",
    "* 여러개의 입력을 받아 하나의 값을 산출하는 모형을 구현합니다. \n",
    "* 여기에서는, 여러개의 단어로 구성된 각각의 문장을 입력으로 받아, 최종적으로 각 문장의 (긍정/ 부정) 감정을 분류하는 모형을 구성합니다.\n",
    "* cf) RNN의 입력과 출력 \n",
    "![inout.png](https://i.stack.imgur.com/b4sus.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624d357",
   "metadata": {},
   "source": [
    "##### Padding \n",
    "* 패딩은 자연어 처리 분야에서 빈번히 사용되는 방식입니다. 이는 입력되는 데이터의 길이를 맞추기 위한 장치입니다. \n",
    "* 예를 들어 단어를 문자단위로 인식해 입력을 전달 받는 모형이 있다고 가정합시다. \n",
    "    - 입력단어 : ['Hello', 'good', 'mad', 'upset', ...] \n",
    "    - 이 경우, 모형을 구성하기 전, 케릭터를 인지할 수 있도록 하나의 인덱스 번호를 제공할 것입니다. \n",
    "    - ex) {0 : 'a', 1 :'b', 2:'c', 3:'d', .... , 26 :'z'} 의 경우로 인덱싱이 이루어져 있다고 가정해봅시다. 이경우, 단어를 인덱스로 표현하면 'Hello' -> [7,4,11,11,14]로, 'mad'는 [12,0,3]으로 다른 길이로 표현될 것입니다. \n",
    "    - 하지만, 우리의 모형은 계산을 위해 항상 일정한 길이의 문자를 받아야 합니다. 이를 위해, 우리는 입력되는 각 단어의 길이를 동일하게 유지해 주어야 할 필요가 있습니다. \n",
    "    - 따라서, 만약 단어의 최대 길이가 10글자 이면, hello 벡터의 경우 5개의 추가적인 문자를, mad는 7개의 추가적인 문자를 공백 대신 입력해 주어야 할 것입니다. \n",
    "    - 하지만, 위에서 선언된 dictionary를 기준으로 인덱싱을 수행하면 해당 글자를 대체할 숫자가 존재하지 않습니다. \n",
    "    - 따라서 dictionary의 첫 항목을 일반적으로 \\<pad\\>로 설정하고 이를 이용해 공백에 대한 인덱싱을 진행합니다. \n",
    "        + ex) {0 : \\'\\<pad>',1 : 'a', 2 :'b', 3:'c', 4:'d', .... , 27 :'z'}\n",
    "        \\-\\-\\> Hello  [8,5,12,12,15] \\-\\-\\> [8,5,12,12,15, 0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf12f41",
   "metadata": {},
   "source": [
    "### 라이브러리 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca806975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연산에 활용합니다 .\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "# 결과를 시각화 하는데 도움을 줍니다. \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow import keras \n",
    "# RNN Cell 등 다양한 layer들을 가지고 있습니다. \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Sequential, Model \n",
    "\n",
    "# 시퀀스를 패딩하는데 도움을 주는 라이브러리 입니다. \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da029b",
   "metadata": {},
   "source": [
    "### Dataset 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ae48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 : 단어 \n",
    "words = ['good', 'bad', 'worse', 'so good']\n",
    "# 출력 : 감정 긍정(1), 부정(0)\n",
    "y_data = [1,0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e8b461",
   "metadata": {},
   "source": [
    "##### 토큰 dictionary 생성 \n",
    "* 문제에 따라 토큰의 단위는 달라질 수 있습니다. \n",
    "    - 여기에서는 각각의 charactor단위를 토큰이라고 보겠습니다\n",
    "* 추후, 단어의 패딩을 위한 \\<pad\\> 토큰을 단어사전의 0번째 자리에 입력합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "460cc7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유일한 글자들만 모아봅니다. \n",
    "char_set = ['<pad>'] + sorted(list(set(''.join(words)))) # 0번 <pad> + ~ \n",
    "\n",
    "# ''.join(words)은 리스트 안의 원소들을 ''안에 들어가는 단위로 구분지어 합해주는 역할을 수행합니다. \n",
    "# 여기에서는, 공백이 없이 연결했음으로, 모든 단어가 연결됩니다. \n",
    "\n",
    "# set()은 기본적으로 합집합 연산을 의미합니다. 따라서, 해당 코드에서는 중복되는 값을 제거한 모든 원소들을 나열합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aee9726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary를 생성합니다. \n",
    "\n",
    "# 인덱스(키): 글자(값)\n",
    "ind2char = {idx : char for idx, char in enumerate(char_set)}\n",
    "\n",
    "# 글자(키) : 인덱스(값)\n",
    "char2idx = {char : idx for idx,char in enumerate(char_set)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca5df64",
   "metadata": {},
   "source": [
    "###### 글자를 숫자의 리스트로 변형하기\n",
    "* 반복문을 통해 순회하며 dictionary.get(key) 메소드를 이용해 해당 자리의 값(숫자)를 받아옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a0fa3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = list(map(lambda word : [char2idx.get(char) for char in word], words))\n",
    "\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f8bfd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7, 7, 4], [3, 2, 4], [10, 7, 8, 9, 5], [9, 7, 1, 6, 7, 7, 4]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda word : words 는 word의 개별 원소에 어떠한 함수를 적용할 때 사용합니다. \n",
    "# 이를 []안에 word로 넘겨주어 함수를 적용합니다. \n",
    "\n",
    "# 반복문으로 풀어 작성한다면 다음과 같습니다 \n",
    "x_data2 = [] \n",
    "for word in words:\n",
    "    temp = [] \n",
    "    for char in word:\n",
    "        temp.append(char2idx.get(char))\n",
    "    x_data2.append(temp)\n",
    "    \n",
    "x_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75c341b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 5, 7]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 데이텀의 길이를 구해보자! \n",
    "# 이는 나중의 패딩을 위한 과정이다. 하지만, 여기에서는 최대 단어의 길이인 7이 아닌 10으로 패딩을 진행할 것이다. \n",
    "x_data_len = list(map(lambda word : len(word), x_data))\n",
    "x_data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d63184",
   "metadata": {},
   "source": [
    "##### padding 진행하기 \n",
    "* max 길이를 10으로 가정하여, 패딩을 진행한다.\n",
    "* pading은 temsorflpw.keras.preprocessing에 위치한 sequence.pad_sequnces로 진행한다. \n",
    "* 패딩의 필요성과 역할은 이전에 언급하였다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec7ac287",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence = 10 \n",
    "x_data = pad_sequences(sequences=x_data, maxlen=max_sequence,\n",
    "                      padding='post', truncating = 'post')\n",
    "\n",
    "# padding -> 문장의 길이가 10보다 작으면 빈 공간을 '뒤에' 채운다 \n",
    "# truncating -> 문장의 길이가 10보다 길면 '뒤'에부터 글자를 잘라낸다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89b95fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7  7  4  0  0  0  0  0  0]\n",
      " [ 3  2  4  0  0  0  0  0  0  0]\n",
      " [10  7  8  9  5  0  0  0  0  0]\n",
      " [ 9  7  1  6  7  7  4  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed522d4",
   "metadata": {},
   "source": [
    "### Model 생성 \n",
    "* Sequential API를 활용한 모형을 구현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdfe5f5",
   "metadata": {},
   "source": [
    "##### Embeding Layer \n",
    "모형을 구성하기 앞서, 자연어 처리 과정에서 Embeding 층의 역할 및 동작 방식에 대해 이해하고 진행해야 함을 느꼈습니다. 참고중인 강의는 해당 부분에 대한 언급이 전무한 관계로 위대한 강의인 [딥 러닝을 이용한 자연어 처리 입문](https://wikidocs.net/33793)의 내용을 참고하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc005a",
   "metadata": {},
   "source": [
    "* word Embeding이란 텍스트 내의 단어들을 밀집 벡터(Dense Vector)로 만드는 것을 말합니다. \n",
    "* cf) 단어를 임베딩 하는 방법에는 **케라스 제공 embeding층**을 이용해 학습데이터를 통해 학습시키는 방식과 **사전훈련된 워드 임베딩**(ex)Word2vec, FastText,GloVe 등)을 이용해 변환하는 방식이 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a15979",
   "metadata": {},
   "source": [
    "* Keras의 Embeding층은 **정수 인코딩이** 되어 있는 단어를 **밀집벡터의** 형태로 변경시켜주는 역할을 수행합니다. (밀집백터는 원핫백터의 희소행렬 문제를 해결하기 위해 조금 더 개선된 방식) \n",
    "![embeding.png](https://wikidocs.net/images/page/33793/lookup_table.PNG)\n",
    "    * **임베딩 층의 입력으로 사용하기 위해서 입력 시퀀스의 각 단어들은 모두 정수 인코딩이 되어있어야 합니다.**\n",
    "\n",
    "    * 어떤 단어 → 단어에 부여된 고유한 정수값 → 임베딩 층 통과 → 밀집 벡터\n",
    "\n",
    "    * 임베딩 층은 입력 정수에 대해 밀집 벡터(dense vector)로 맵핑하고 이 밀집 벡터는 인공 신경망의 학습 과정에서 가중치가 학습되는 것과 같은 방식으로 훈련됩니다. 훈련 과정에서 단어는 모델이 풀고자하는 작업에 맞는 값으로 업데이트 됩니다. 그리고 이 밀집 벡터를 임베딩 벡터라고 부릅니다.\n",
    "\n",
    "    * 정수를 밀집 벡터 또는 임베딩 벡터로 맵핑한다는 것은 어떤 의미일까요? 특정 단어와 맵핑되는 정수를 인덱스로 가지는 테이블로부터 임베딩 벡터 값을 가져오는 룩업 테이블이라고 볼 수 있습니다. 그리고 이 테이블은 단어 집합의 크기만큼의 행을 가지므로 모든 단어는 고유한 임베딩 벡터를 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b76cd0",
   "metadata": {},
   "source": [
    "아직 이해가 되지 않습니다.. 텐서플로우에서 제공하는 공식 튜토리얼을 살펴봅니다.  \n",
    "\n",
    "[Tensorflow_tutorial](https://www.tensorflow.org/text/guide/word_embeddings?hl=ko)  \n",
    "![dkgk.png](https://www.tensorflow.org/text/guide/images/embedding2.png?hl=ko) \n",
    "* 단어 임베딩 방식은, 우리가 최초 입력으로 지정한 임의의 차원으로 Dense Vector의 차원을 축소해 줍니다. \n",
    "* 각 단어는 서로의 관계에 따라 각 차원에서 수치의 값을 받게 됩니다. \n",
    "![dkgk2.ong](https://www.tensorflow.org/text/guide/images/embedding.jpg?hl=ko)\n",
    "예를들어, 위의 그림에서 cat이라는 단어는 1번째 주성분에서는 1.2의 값을, 2번째 주성분에서는 -0.1의 값을 가집니다. 해당 자리의 값들은 모형이 학습을 진행하면서 자동적으로 같이 학습이 진행됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223839e9",
   "metadata": {},
   "source": [
    "* 우리가 모형에서 사용하는 embeding layer의 정보는 다음과 같습니다. \n",
    "input_dim = len(char2idx)  \n",
    "output_dim = len(char2idx)  \n",
    "one_hot = np.eye(len(char2idx))  \n",
    "hidden_size = 10  \n",
    "num_classes = 2  \n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
    "                           trainable=False, mask_zero=True,  \n",
    "                           input_length=max_sequence,                                   embeddings_initializer=keras.initializers.Constant(one_hot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415265f",
   "metadata": {},
   "source": [
    "이때, input_dim이 단어사전의 크기인 이유는, 우리의 데이터 형태와 관련이 있습니다.  \n",
    "1. 만약 입력이 'good'이라는 단어 즉, [6, 7, 7, 8]의 형태라고 가정해 봅시다. \n",
    "2. 이때, Embeding layer에는 각 글자가 들어올 것이고, 이를 하나의 벡터로 만들어야 합니다. 6 -> [........] \n",
    "3. 하나의 char이 원핫벡터로 표현되기 위해서는 , 최대 단어사전 길이 만큼의 공간이 필요합니다. \n",
    "4. 여기에서는 0으로 단어사전의 길이 만큼 채워진 벡터를 입력으로 초기화해 넘겨주고, 이를 변환하는 과정을 거칩니다. \n",
    "5. output dim을 단어사전의 크기로 지정한것은 밀집벡터가 아닌 원핫벡터로의 변형을 목적으로 한다는것을 의미합니다. \n",
    "6. 따라서 모형이 학습되는 과정에서 해당 층은 학습이 일어날 필요가 없습니다(단순한 원핫벡터를 리턴하기때문) --> trainable = False \n",
    "7. input_length는 각 단어가 분할적으로 입력되기 때문에 sequence의 길이를 입력해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66422c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating simple rnn for \"many to one\" classification\n",
    "input_dim = len(char2idx)\n",
    "output_dim = len(char2idx)\n",
    "one_hot = np.eye(len(char2idx))\n",
    "hidden_size = 10\n",
    "num_classes = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
    "                           trainable=False, mask_zero=True, input_length=max_sequence,\n",
    "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_size))\n",
    "model.add(layers.Dense(units=num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ded81d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 11)            121       \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 10)                220       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 363\n",
      "Trainable params: 242\n",
      "Non-trainable params: 121\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890d1ef",
   "metadata": {},
   "source": [
    "### Loss 함수 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc410009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating loss function\n",
    "def loss_fn(model, x, y):\n",
    "    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y_true=y, y_pred=model(x), from_logits=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a17d56",
   "metadata": {},
   "source": [
    "분류 문제를 푸는것이기 때문에 cross entropy를 구해주는 api를 활용합니다.  \n",
    "특히, 우리가 마지막으로 얻는 값이 01의 값이 아닌 integer형으로 구성된 벡터 구조를 비교하는것이기 때문에 sqparse_categorical_crossentropy를 활용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f861a74",
   "metadata": {},
   "source": [
    "### 모형학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87576977",
   "metadata": {},
   "source": [
    "##### Hyper Params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8600653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .01\n",
    "epochs = 30\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f744e",
   "metadata": {},
   "source": [
    "##### optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fe80752",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefcdae",
   "metadata": {},
   "source": [
    "##### 데이터 파이프라인 생성 \n",
    "* 데이터를 베치 단위로 끊어 입력해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3ab2397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 10), (None,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# generating data pipeline\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data)) # 데이터를 문제와 답으로 함꼐 엮어줍니다. \n",
    "tr_dataset = tr_dataset.shuffle(buffer_size = 4)  # 버퍼를 이용해 데이터를 섞어줍니다. \n",
    "tr_dataset = tr_dataset.batch(batch_size = batch_size) # 배치 크기 만큼씩 데이터를 입력해줍니다. \n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5768fc6b",
   "metadata": {},
   "source": [
    "##### 실제 학습과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7546f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.239\n",
      "epoch :  10, tr_loss : 0.045\n",
      "epoch :  15, tr_loss : 0.016\n",
      "epoch :  20, tr_loss : 0.009\n",
      "epoch :  25, tr_loss : 0.006\n",
      "epoch :  30, tr_loss : 0.005\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 ==0:        \n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb22c5",
   "metadata": {},
   "source": [
    "### 성능 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6708f425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 100.00%\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1)\n",
    "print('acc : {:.2%}'.format(np.mean(yhat == y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d4d64c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1614f591370>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf527f68",
   "metadata": {},
   "source": [
    "# many to one Stacking \n",
    "* 여러 층으로 구성된 RNN모형을 생성하여, 예측의 성능을 향상시킵니다. \n",
    "![stackedRNN.png](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbe5HZi%2FbtqDx6bOf9K%2F6PWk0BUenrK1WPeZ4sZihK%2Fimg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216e356",
   "metadata": {},
   "source": [
    "모형의 목적은 특정 문장을 인식하고, 해당 명언을 richard feynma이 한 말인지, albert einstein이 한 말인지 분류해 주는 모형입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e637d8f",
   "metadata": {},
   "source": [
    "## 필수 라이브러리 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f314e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "# from pprint import pprint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93bb6f7",
   "metadata": {},
   "source": [
    "## 데이터 준비하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00185781",
   "metadata": {},
   "source": [
    "### 입력 데이터 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b5eaabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['What I cannot create, I do not understand.',\n",
    "            'Intellecuals solve problems, geniuses prevent them',\n",
    "             'A person who never made a mistake never tied anything new.',\n",
    "             'The same equations have the same solutions.']\n",
    "\n",
    "y_data = [1,0,0,1] # 1: richard feynman, 0: albert einstein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e1c2f2",
   "metadata": {},
   "source": [
    "### 토큰 사전 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab6f06d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', ' ', ',', '.', 'A', 'I', 'T', 'W', 'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
     ]
    }
   ],
   "source": [
    "# 유일한 문자들만 추려내기 \n",
    "char_set = ['<pad>'] + sorted(list(set(''.join(sentences))))\n",
    "print(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63e5a2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: ' ', 2: ',', 3: '.', 4: 'A', 5: 'I', 6: 'T', 7: 'W', 8: 'a', 9: 'b', 10: 'c', 11: 'd', 12: 'e', 13: 'g', 14: 'h', 15: 'i', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'y'}\n",
      "{'<pad>': 0, ' ': 1, ',': 2, '.': 3, 'A': 4, 'I': 5, 'T': 6, 'W': 7, 'a': 8, 'b': 9, 'c': 10, 'd': 11, 'e': 12, 'g': 13, 'h': 14, 'i': 15, 'k': 16, 'l': 17, 'm': 18, 'n': 19, 'o': 20, 'p': 21, 'q': 22, 'r': 23, 's': 24, 't': 25, 'u': 26, 'v': 27, 'w': 28, 'y': 29}\n"
     ]
    }
   ],
   "source": [
    "# 문자마다 고유의 번호 지정 \n",
    "\n",
    "# 결과 디코딩시 필요 \n",
    "idx2char = {idx : char for idx,char in enumerate(char_set)}\n",
    "# 숫자로 인코딩시 사용 \n",
    "char2idx = {char:idx for idx, char in enumerate(char_set)}\n",
    "\n",
    "print(idx2char)\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2660fa2",
   "metadata": {},
   "source": [
    "### 문장 시퀀스를 숫자의 배열로 변환하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36a1e56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7,\n",
       "  14,\n",
       "  8,\n",
       "  25,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  10,\n",
       "  8,\n",
       "  19,\n",
       "  19,\n",
       "  20,\n",
       "  25,\n",
       "  1,\n",
       "  10,\n",
       "  23,\n",
       "  12,\n",
       "  8,\n",
       "  25,\n",
       "  12,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  1,\n",
       "  11,\n",
       "  20,\n",
       "  1,\n",
       "  19,\n",
       "  20,\n",
       "  25,\n",
       "  1,\n",
       "  26,\n",
       "  19,\n",
       "  11,\n",
       "  12,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  8,\n",
       "  19,\n",
       "  11,\n",
       "  3],\n",
       " [5,\n",
       "  19,\n",
       "  25,\n",
       "  12,\n",
       "  17,\n",
       "  17,\n",
       "  12,\n",
       "  10,\n",
       "  26,\n",
       "  8,\n",
       "  17,\n",
       "  24,\n",
       "  1,\n",
       "  24,\n",
       "  20,\n",
       "  17,\n",
       "  27,\n",
       "  12,\n",
       "  1,\n",
       "  21,\n",
       "  23,\n",
       "  20,\n",
       "  9,\n",
       "  17,\n",
       "  12,\n",
       "  18,\n",
       "  24,\n",
       "  2,\n",
       "  1,\n",
       "  13,\n",
       "  12,\n",
       "  19,\n",
       "  15,\n",
       "  26,\n",
       "  24,\n",
       "  12,\n",
       "  24,\n",
       "  1,\n",
       "  21,\n",
       "  23,\n",
       "  12,\n",
       "  27,\n",
       "  12,\n",
       "  19,\n",
       "  25,\n",
       "  1,\n",
       "  25,\n",
       "  14,\n",
       "  12,\n",
       "  18],\n",
       " [4,\n",
       "  1,\n",
       "  21,\n",
       "  12,\n",
       "  23,\n",
       "  24,\n",
       "  20,\n",
       "  19,\n",
       "  1,\n",
       "  28,\n",
       "  14,\n",
       "  20,\n",
       "  1,\n",
       "  19,\n",
       "  12,\n",
       "  27,\n",
       "  12,\n",
       "  23,\n",
       "  1,\n",
       "  18,\n",
       "  8,\n",
       "  11,\n",
       "  12,\n",
       "  1,\n",
       "  8,\n",
       "  1,\n",
       "  18,\n",
       "  15,\n",
       "  24,\n",
       "  25,\n",
       "  8,\n",
       "  16,\n",
       "  12,\n",
       "  1,\n",
       "  19,\n",
       "  12,\n",
       "  27,\n",
       "  12,\n",
       "  23,\n",
       "  1,\n",
       "  25,\n",
       "  15,\n",
       "  12,\n",
       "  11,\n",
       "  1,\n",
       "  8,\n",
       "  19,\n",
       "  29,\n",
       "  25,\n",
       "  14,\n",
       "  15,\n",
       "  19,\n",
       "  13,\n",
       "  1,\n",
       "  19,\n",
       "  12,\n",
       "  28,\n",
       "  3],\n",
       " [6,\n",
       "  14,\n",
       "  12,\n",
       "  1,\n",
       "  24,\n",
       "  8,\n",
       "  18,\n",
       "  12,\n",
       "  1,\n",
       "  12,\n",
       "  22,\n",
       "  26,\n",
       "  8,\n",
       "  25,\n",
       "  15,\n",
       "  20,\n",
       "  19,\n",
       "  24,\n",
       "  1,\n",
       "  14,\n",
       "  8,\n",
       "  27,\n",
       "  12,\n",
       "  1,\n",
       "  25,\n",
       "  14,\n",
       "  12,\n",
       "  1,\n",
       "  24,\n",
       "  8,\n",
       "  18,\n",
       "  12,\n",
       "  1,\n",
       "  24,\n",
       "  20,\n",
       "  17,\n",
       "  26,\n",
       "  25,\n",
       "  15,\n",
       "  20,\n",
       "  19,\n",
       "  24,\n",
       "  3]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = list(map(lambda sentence : [char2idx.get(char) for char in sentence], sentences))\n",
    "\n",
    "x_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "caa9bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 50, 58, 43]\n"
     ]
    }
   ],
   "source": [
    "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
    "print(x_data_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dbfa0d",
   "metadata": {},
   "source": [
    "### padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3a6608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7 14  8 25  1  5  1 10  8 19 19 20 25  1 10 23 12  8 25 12  2  1  5  1\n",
      "  11 20  1 19 20 25  1 26 19 11 12 23 24 25  8 19 11  3  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 5 19 25 12 17 17 12 10 26  8 17 24  1 24 20 17 27 12  1 21 23 20  9 17\n",
      "  12 18 24  2  1 13 12 19 15 26 24 12 24  1 21 23 12 27 12 19 25  1 25 14\n",
      "  12 18  0  0  0  0  0]\n",
      " [ 4  1 21 12 23 24 20 19  1 28 14 20  1 19 12 27 12 23  1 18  8 11 12  1\n",
      "   8  1 18 15 24 25  8 16 12  1 19 12 27 12 23  1 25 15 12 11  1  8 19 29\n",
      "  25 14 15 19 13  1 19]\n",
      " [ 6 14 12  1 24  8 18 12  1 12 22 26  8 25 15 20 19 24  1 14  8 27 12  1\n",
      "  25 14 12  1 24  8 18 12  1 24 20 17 26 25 15 20 19 24  3  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]]\n",
      "[42, 50, 58, 43]\n",
      "[1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "max_sequence = 55 \n",
    "\n",
    "x_data = pad_sequences(sequences=x_data, maxlen= max_sequence,\n",
    "                      padding = 'post', truncating = 'post')\n",
    "\n",
    "print(x_data)\n",
    "print(x_data_len)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ed6b30",
   "metadata": {},
   "source": [
    "## 모형 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a15f1",
   "metadata": {},
   "source": [
    "#####  Hyper Params. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f915a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 출력 게이트 수 \n",
    "num_classes = 2 \n",
    "# hidden dimension \n",
    "hidden_dims = [10,10]\n",
    "\n",
    "# embeding층 입력 \n",
    "input_dim = output_dim = len(char2idx)\n",
    "one_hot = np.eye(len(char2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3512c8ee",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim,\n",
    "                          trainable=False, mask_zero = True,\n",
    "                          input_length=max_sequence,\n",
    "                          embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_dims[0], return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dropout(rate=0.2)))\n",
    "model.add(layers.SimpleRNN(units=hidden_dims[1]))\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "model.add(layers.Dense(units=num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6e165",
   "metadata": {},
   "source": [
    "Return Sequence는 첫번째 층의 각 시점에서의 hidden state을 다음 층의 입력으로 전달하기 위함 입니다. 이때, Dropout을 적용해도 각 시점의 hidden값이 정확하게 다음 층으로 전달할 수 있도록 도와주는 API가 TimeDistributed 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36245ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 55, 30)            900       \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 55, 10)            410       \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 55, 10)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 1,542\n",
      "Trainable params: 642\n",
      "Non-trainable params: 900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd56104",
   "metadata": {},
   "source": [
    "## Training!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f729c7",
   "metadata": {},
   "source": [
    "### loss의 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "409aa237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x, y, training):    \n",
    "    return tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y_true=y, y_pred=model(x, training), from_logits=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40defbc4",
   "metadata": {},
   "source": [
    "### 하이퍼~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85373477",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = .01\n",
    "epochs = 30\n",
    "batch_size = 2\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a05ffb8",
   "metadata": {},
   "source": [
    "### 데이터 파이프라이 심자! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "339be008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 55), (None,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
    "tr_dataset = tr_dataset.batch(batch_size=batch_size)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863714be",
   "metadata": {},
   "source": [
    "### 반복문을 활용한 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48916041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.093\n",
      "epoch :  10, tr_loss : 0.022\n",
      "epoch :  15, tr_loss : 0.013\n",
      "epoch :  20, tr_loss : 0.007\n",
      "epoch :  25, tr_loss : 0.005\n",
      "epoch :  30, tr_loss : 0.005\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, training=True)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 ==0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e993ff",
   "metadata": {},
   "source": [
    "## 성능 측정하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50b58d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 100.00%\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1)\n",
    "print('accuracy : {:.2%}'.format(np.mean(yhat == y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bc1805d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16150edddf0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e28d5",
   "metadata": {},
   "source": [
    "# many to many \n",
    "* 문장 속 각 단어의 품사를 테깅해주는 형태소 분석기를 생성하는 예제를 만듭니다. \n",
    "* many to many 예제는 하나의 시퀀스 내에 있는 모든 은닉상태 값을 각각 출력해 각각의 예측을 수행합니다. \n",
    "* 또한, 각각의 토큰에 대한 예측과 해당 토큰의 실제 값을 비교하여 각각의 loss를 계산한 후, 이를 시퀀스 단위로 평균을 계산하여 Gradient Descent를 계산하고 이를 back propogation을 통해 가중치를 수정하는데 활용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5eef4f",
   "metadata": {},
   "source": [
    "![sequenceTagging.png](https://miro.medium.com/max/1838/1*_p0fvCt7noN7j6bXQcZjtQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6d7b0",
   "metadata": {},
   "source": [
    "* sequence tagging의 대략적인 진행 방식은 아래의 그림과 같습니다. \n",
    "![SequenceTag.png](https://miro.medium.com/max/1400/1*3Lnln1txs1lys6fwbVKsJA.png)\n",
    "이러한 품사테깅을 위해서는 2개의 인덱싱 딕셔너리가 필요합니다.   \n",
    "    - 토큰의 정수 인덱스와 값을 담을 dict,, \n",
    "    - 정답으로 활용할 품사와 그에대한 키 인덱스가 포함되는 dict. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab3aee",
   "metadata": {},
   "source": [
    "##### Masking \n",
    "* 시퀀스의 모든 token을 활용해 예측과 연산, loss의 계산을 진행하는 특성에 의해 우리는 Masking 작업을 진행해야 합니다. \n",
    "* masking이란 우리가 sequence의 길이를 맞추기 위해 Padding작업을 수행할때 포함시킨 \\<pad\\>토큰을 loss에서 고려하지 않는 것을 말합니다. \n",
    "* 패딩을 수행할때, \\<pad\\>토큰에 대한 정보를 1과0으로 이루어진 벡터로 생성하고, loss를 계산할때, 각각의 토큰의 로스가 담긴 배열과의 element wise(원소끼리의 곱)을 통해 연산에서 제외해주는 방식을 의미합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efff3202",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b4d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow import keras \n",
    "from  tensorflow.keras import layers \n",
    "from tensorflow.keras import Sequential, Model \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f53d0",
   "metadata": {},
   "source": [
    "## 데이터 준비하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a61618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어로 이루어진 토큰으로 이루어진 문장의 vector로 구성된 matrix\n",
    "sentences = [['I', 'feel', 'hungry'],\n",
    "             ['tensorflow', 'is', 'very', 'difficult'],\n",
    "             ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "             ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "\n",
    "# 각각의 토큰의 품사(정답) \n",
    "pos = [['pronoun', 'verb', 'adjective'],\n",
    "       ['noun', 'verb', 'adverb', 'adjective'],\n",
    "       ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
    "       ['noun', 'verb', 'adverb', 'adjective', 'verb']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5726d",
   "metadata": {},
   "source": [
    "## dataset 전처리 \n",
    "* 토큰에 대한 dict \n",
    "* 품사에 대한 dict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f109d376",
   "metadata": {},
   "source": [
    "### Token dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f81836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'feel',\n",
       " 'hungry',\n",
       " 'tensorflow',\n",
       " 'is',\n",
       " 'very',\n",
       " 'difficult',\n",
       " 'tensorflow',\n",
       " 'is',\n",
       " 'a',\n",
       " 'framework',\n",
       " 'for',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'tensorflow',\n",
       " 'is',\n",
       " 'very',\n",
       " 'fast',\n",
       " 'changing']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = sum(sentences,[])\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a785be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'a',\n",
       " 'changing',\n",
       " 'deep',\n",
       " 'difficult',\n",
       " 'fast',\n",
       " 'feel',\n",
       " 'for',\n",
       " 'framework',\n",
       " 'hungry',\n",
       " 'is',\n",
       " 'learning',\n",
       " 'tensorflow',\n",
       " 'very']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 제거 \n",
    "word_list = sorted(set(word_list))\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61ee161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
      "{0: '<pad>', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# 페트토큰 추가 \n",
    "word_list = ['<pad>'] + word_list \n",
    "\n",
    "# 딕셔너리 생성 \n",
    "word2idx = {word: idx for idx,word in enumerate(word_list)}\n",
    "idx2word = {idx: word for idx,word in enumerate(word_list)}\n",
    "\n",
    "print(word2idx)\n",
    "print(idx2word)\n",
    "print(len(word2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e392d",
   "metadata": {},
   "source": [
    "### dict. for part of speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eadb2af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
      "{0: '<pad>', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# 하나의 배열로 만들기 \n",
    "pos_list = sum(pos,[])\n",
    "# 중복 제거 및 정렬 \n",
    "pos_list = sorted(set(pos_list))\n",
    "# 패드토큰 추가 \n",
    "pos_list = [\"<pad>\"] + pos_list\n",
    "\n",
    "# 사전 구성 \n",
    "pos2idx = {pos : idx for idx,pos in enumerate(pos_list)}\n",
    "idx2pos = {idx : pos for idx,pos in enumerate(pos_list)}\n",
    "\n",
    "print(pos2idx)\n",
    "print(idx2pos)\n",
    "print(len(pos2idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7266175",
   "metadata": {},
   "source": [
    "### 정수 인코딩 및 Padding 진행 \n",
    "* 중요!! - 패딩을 진행할때, padding이 아닌 자리를 기억할 x_data_mask 를 생성합니다. \n",
    "* 또한, 실제 문장의 길이를 기억할 유효 자리수에 대한 정보도 기억해 주어야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05da5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "[[6 7 1 0 0 0 0 0 0 0]\n",
      " [4 7 2 1 0 0 0 0 0 0]\n",
      " [4 7 3 4 5 1 4 0 0 0]\n",
      " [4 7 2 1 7 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 문장의 최대 길이 설정 \n",
    "max_sequence = 10 \n",
    "\n",
    "# 정수 인코딩 진행 \n",
    "x_data = list(map(lambda sentence: [word2idx.get(token) for token in sentence], sentences))\n",
    "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))\n",
    "\n",
    "# 패딩 진행, 동시에 패딩 과정에 대한 정보를 저장합니다, \n",
    "x_data = pad_sequences(sequences=x_data, maxlen=max_sequence, padding='post')\n",
    "## 이부분! \n",
    "x_data_mask = ((x_data != 0)*1).astype(np.float32)\n",
    "x_data_len = list(map(lambda sentence : len(sentence), sentences))\n",
    "\n",
    "y_data = pad_sequences(sequences=y_data, maxlen=max_sequence, padding='post')\n",
    "\n",
    "print(x_data, x_data_len)\n",
    "print(x_data_mask)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8bfd34",
   "metadata": {},
   "source": [
    "## 모형 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d01dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating rnn for \"many to many\" sequence tagging\n",
    "num_classes = len(pos2idx)\n",
    "hidden_dim = 10\n",
    "\n",
    "input_dim = len(word2idx)\n",
    "output_dim = len(word2idx)\n",
    "one_hot = np.eye(len(word2idx))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True,\n",
    "                           trainable=False, input_length=max_sequence,\n",
    "                           embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.SimpleRNN(units=hidden_dim, return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(units=num_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387d801",
   "metadata": {},
   "source": [
    "모든 시퀀스에서 정답을 내야 하므로 Return seuence를 통해 모든 은닉상태를 출력하고, 이를 모두 각각 Dense층으로 TimeDistributed를 통해 매칭해 전달하여, 최종적인 값을 도출했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b65277a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x000001ABFFDBA6D0>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a5597d",
   "metadata": {},
   "source": [
    "## 학습 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7b66a0",
   "metadata": {},
   "source": [
    "### loss 함수 정의 \n",
    "* 기본적인 컨셉은 sequence내의 모든 토큰에 대해, 예측과 실제를 비교하는 것입니다. \n",
    "* 이때, pad토큰은 연산에서 제외되어야 합니다. \n",
    "* 따라서, pad에 대한 loss에는 0을, 그 외에는 1을 곱해 pad에 대한 loss를 제외하고 이 값들을 모두 더하는 과정을 거칩니다. \n",
    "* 도출된 값을 pad를 제외한 유효 문장길이로 나누어 평균을 계산합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92444617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x, y, x_len, max_sequence):\n",
    "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
    "    valid_time_step = tf.cast(x_len,dtype=tf.float32)    \n",
    "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y_true=y, y_pred=model(x), from_logits=True) * masking    \n",
    "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step    \n",
    "    sequence_loss = tf.reduce_mean(sequence_loss)    \n",
    "    return sequence_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebfbc9",
   "metadata": {},
   "source": [
    "### Hyper Params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa64ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1 \n",
    "epochs = 30 \n",
    "batch_size = 2 \n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d89b8",
   "metadata": {},
   "source": [
    "### make data pipline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c5f3b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 10), (None, 10), (None,)), types: (tf.int32, tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((x_data,y_data,x_data_len))\n",
    "training_dataset = training_dataset.shuffle(buffer_size = 4)\n",
    "training_dataset = training_dataset.batch(batch_size=2)\n",
    "\n",
    "print(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca323e5",
   "metadata": {},
   "source": [
    "### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d822d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.224\n",
      "epoch :  10, tr_loss : 0.011\n",
      "epoch :  15, tr_loss : 0.003\n",
      "epoch :  20, tr_loss : 0.001\n",
      "epoch :  25, tr_loss : 0.001\n",
      "epoch :  30, tr_loss : 0.001\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb, x_mb_len in training_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d61f9e",
   "metadata": {},
   "source": [
    "## 결과 확인하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c5ee932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pronoun', 'verb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
      "[['pronoun', 'verb', 'adjective'],\n",
      " ['noun', 'verb', 'adverb', 'adjective'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
    "\n",
    "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
    "pprint(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6e7b587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ab8315d040>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b68433",
   "metadata": {},
   "source": [
    "# Bidirectional RNN (Many 2 Many) \n",
    "![bidirectional.png](https://miro.medium.com/max/1313/1*6QnPUSv_t9BY9Fv8_aLb-Q.png) \n",
    "* 양방향 RNN은 우리가 기존에 사용하던 RNN모형과 큰 차이가 존재합니다. 바로, 기존의 RNN이 은닉상태의 값을 단순히 앞에서 뒤로 전달하는 forward RNN 방식으로 작동하는 점과 다르게, Forward 방향과 Backward방향으로 동시에 은닉상태의 값을 전달하는 rnn 모형을 구성하는것 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d02f76",
   "metadata": {},
   "source": [
    "* 해당 방식의 모형 구현은 기존의 모형의 각각의 은닉상태에서의 **정보의 양에 대한 불균형성**에서 비롯되었습니다. \n",
    "![bidirection2.png](https://blog.kakaocdn.net/dn/bPTdDN/btqDCb3soJP/615rYSKGD0OL6F3YmwBoSk/img.png) \n",
    "* 위의 그림은 정보의 불균형에 대한 기존 방식의 문제점과 bidirection model이 이를 해결해주는 방식을 자세히 보여줍니다. \n",
    "    - 기존의 forward방식만을 사용하면, 각 hidden state가 가지고 있는 정보의 양은 시점에 따라 크게 달라집니다. 첫번째 hidden state는 첫번째 입력에 대한 정보, 즉 1만큼의 정보만을 가지고 연산을 수행하는 반면에, 두번째 hidden state는 첫번째 층에서 전달된 이전시점의 hidden state에 대한 정보와 해당시점에서의 입력에 대한 정보를 포함해 총 2의 크기의 정보를 가지고 연산을 수행합니다. \n",
    "    - 이는 sequence의 길이가 길어질수록 중대한 문제가 됩니다. \n",
    "    - 또한, many to many모형에서는 특히, 정보의 양이 상대적으로 부족한 sequence의 초기 부분에서의 예측 및 분류 성능은 크게 떨어진다는 문제점을 지니고 있습니다.\n",
    "* Bidirectional Model은 정보를 뒤에서부터 읽는 backward방식의 계층을 추가적으로 사용하여, 각 시점에서의 hidden state를 계산할때 사용되는 정보의 양을 일정하게 유지해줍니다. \n",
    "    - 각 시점에서의 은닉상태의 계산에 있어, 각 시점에서 forward방식으로 도출된 값과 backward 방식으로 도출된 값을 모두 이용해 연산을 수행합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1635f3",
   "metadata": {},
   "source": [
    "* 구체적인 은닉상태의 계산방식은 아래와 같습니다. \n",
    "![cal_bidirection.png](https://blog.kakaocdn.net/dn/rOK7v/btqDyE0uYPz/1yO1crLwWks7nKIZBK9A0K/img.png)\n",
    "1. 해당시점에서 각각 Forward방식과 Backward 방식으로 도출된 은닉상태의 값을 concat하여 새로운 형태의 vector를 생성합니다. \n",
    "2. 새로운 vector에 weight와 bias를 붙여 예측값을 도출합니다. \n",
    "(단, weight와 bias matrix는 모든 sequence에서 공통으로 사용합니다.)  \n",
    "\n",
    "* loss의 계산은 기존의 many to many방식에서와 동일하게 각 은닉상태에 대한 loss를 계산하고, 이를 sequence별로 평균을 적용해 backpropogation을 진행합니다. \n",
    "* 또한 pad토큰에 대해 masking을 적용하는 방식도 이전과 동일합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d98ab27",
   "metadata": {},
   "source": [
    "**설명은 다소 복잡할 수 있지만, 실제 구현에 있어서의 변경사항은 모형 구현시 한줄의 수정만 있으면 가능합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70928beb",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d366c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import Sequential, Model \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b931bcd",
   "metadata": {},
   "source": [
    "## 데이터 준비하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f5ea214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전의 문제와 동일한 예제를 풀이합니다.  \n",
    "# example data\n",
    "sentences = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "pos = [['pronoun', 'verb', 'adjective'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective'],\n",
    "     ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
    "     ['noun', 'verb', 'adverb', 'adjective', 'verb']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377bbc36",
   "metadata": {},
   "source": [
    "## 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80ee193a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n",
      "{0: '<pad>', 1: 'I', 2: 'a', 3: 'changing', 4: 'deep', 5: 'difficult', 6: 'fast', 7: 'feel', 8: 'for', 9: 'framework', 10: 'hungry', 11: 'is', 12: 'learning', 13: 'tensorflow', 14: 'very'}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# token dictionary 생성하기 \n",
    "word_list = sum(sentences, [])\n",
    "word_list = sorted(set(word_list))\n",
    "word_list = ['<pad>'] + word_list\n",
    "\n",
    "word2idx = {word:idx for idx, word in enumerate(word_list)}\n",
    "idx2word = {idx:word for idx, word in enumerate(word_list)}\n",
    "\n",
    "print(word2idx)\n",
    "print(idx2word)\n",
    "print(len(idx2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "729e00e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'adjective': 1, 'adverb': 2, 'determiner': 3, 'noun': 4, 'preposition': 5, 'pronoun': 6, 'verb': 7}\n",
      "{0: '<pad>', 1: 'adjective', 2: 'adverb', 3: 'determiner', 4: 'noun', 5: 'preposition', 6: 'pronoun', 7: 'verb'}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# 품사 dict 생성하기 \n",
    "pos_list = sum(pos,[])\n",
    "pos_list = sorted(set(pos_list))\n",
    "pos_list = ['<pad>'] + pos_list \n",
    "\n",
    "pos2idx = {pos:idx for idx,pos in enumerate(pos_list)}\n",
    "idx2pos = {idx:pos for idx,pos in enumerate(pos_list)}\n",
    "\n",
    "print(pos2idx)\n",
    "print(idx2pos)\n",
    "print(len(pos2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "399c73da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 배열을 정수 인코딩 하여 데이터 생성하기 \n",
    "max_sequence = 10 \n",
    "x_data = list(map(lambda sentence: [word2idx.get(token) for token in sentence], sentences))\n",
    "y_data = list(map(lambda sentence : [pos2idx.get(token) for token in sentence], pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "658950c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding 진행하기, 이에 대한 정보를 담을 데이터도 생성합니다. \n",
    "x_data = pad_sequences(sequences=x_data, maxlen=max_sequence, padding='post')\n",
    "\n",
    "# 마스크 정보 및 데이터의 유효길이 담아두기 \n",
    "x_data_mask = ((x_data != 0)*1).astype(np.float32)\n",
    "x_data_len = list(map(lambda sentence : len(sentence), sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b542349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y데이터 패딩 \n",
    "y_data = pad_sequences(sequences=y_data, maxlen=max_sequence, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a0a0fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]] [3, 4, 7, 5]\n",
      "[[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
      "[[6 7 1 0 0 0 0 0 0 0]\n",
      " [4 7 2 1 0 0 0 0 0 0]\n",
      " [4 7 3 4 5 1 4 0 0 0]\n",
      " [4 7 2 1 7 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# checking data\n",
    "print(x_data, x_data_len)\n",
    "print(x_data_mask)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eac472",
   "metadata": {},
   "source": [
    "## 모형 생성하기 \n",
    "* 기존의 rnn층을 Bidirectional로 감싸주면 간단하게 구현이 가능합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2da823b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bidirectional rnn for \"many to many\" sequence tagging\n",
    "num_classes = len(pos2idx)\n",
    "hidden_dim = 10\n",
    "\n",
    "input_dim = len(word2idx)\n",
    "output_dim = len(word2idx)\n",
    "one_hot = np.eye(len(word2idx))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(max_sequence,)))\n",
    "model.add(layers.Embedding(input_dim=input_dim, output_dim=output_dim, mask_zero=True,\n",
    "                                 trainable=False, input_length=max_sequence,\n",
    "                                 embeddings_initializer=keras.initializers.Constant(one_hot)))\n",
    "model.add(layers.Bidirectional(keras.layers.SimpleRNN(units=hidden_dim, return_sequences=True)))\n",
    "model.add(layers.TimeDistributed(keras.layers.Dense(units=num_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e6af78",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19dee6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating loss function\n",
    "def loss_fn(model, x, y, x_len, max_sequence):\n",
    "    masking = tf.sequence_mask(x_len, maxlen=max_sequence, dtype=tf.float32)\n",
    "    valid_time_step = tf.cast(x_len,dtype=tf.float32)\n",
    "    sequence_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y_true=y, y_pred=model(x), from_logits=True) * masking    \n",
    "    sequence_loss = tf.reduce_sum(sequence_loss, axis=-1) / valid_time_step\n",
    "    sequence_loss = tf.reduce_mean(sequence_loss)\n",
    "    return sequence_loss\n",
    "\n",
    "# creating and optimizer\n",
    "lr = 0.1\n",
    "epochs = 30\n",
    "batch_size = 2 \n",
    "opt = tf.keras.optimizers.Adam(learning_rate = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb2fed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 10), (None, 10), (None,)), types: (tf.int32, tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# generating data pipeline\n",
    "tr_dataset = tf.data.Dataset.from_tensor_slices((x_data, y_data, x_data_len))\n",
    "tr_dataset = tr_dataset.shuffle(buffer_size=4)\n",
    "tr_dataset = tr_dataset.batch(batch_size = 2)\n",
    "\n",
    "print(tr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45d141e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   5, tr_loss : 0.008\n",
      "epoch :  10, tr_loss : 0.000\n",
      "epoch :  15, tr_loss : 0.000\n",
      "epoch :  20, tr_loss : 0.000\n",
      "epoch :  25, tr_loss : 0.000\n",
      "epoch :  30, tr_loss : 0.000\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "tr_loss_hist = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_tr_loss = 0\n",
    "    tr_step = 0\n",
    "    \n",
    "    for x_mb, y_mb, x_mb_len in tr_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            tr_loss = loss_fn(model, x=x_mb, y=y_mb, x_len=x_mb_len, max_sequence=max_sequence)\n",
    "        grads = tape.gradient(target=tr_loss, sources=model.variables)\n",
    "        opt.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "        avg_tr_loss += tr_loss\n",
    "        tr_step += 1\n",
    "    else:\n",
    "        avg_tr_loss /= tr_step\n",
    "        tr_loss_hist.append(avg_tr_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch : {:3}, tr_loss : {:.3f}'.format(epoch + 1, avg_tr_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27fa505",
   "metadata": {},
   "source": [
    "## 성능 확인하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fecdbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['pronoun', 'verb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun', '<pad>', '<pad>', '<pad>'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n",
      "[['pronoun', 'verb', 'adjective'],\n",
      " ['noun', 'verb', 'adverb', 'adjective'],\n",
      " ['noun', 'verb', 'determiner', 'noun', 'preposition', 'adjective', 'noun'],\n",
      " ['noun', 'verb', 'adverb', 'adjective', 'verb']]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(x_data)\n",
    "yhat = np.argmax(yhat, axis=-1) * x_data_mask\n",
    "\n",
    "pprint(list(map(lambda row : [idx2pos.get(elm) for elm in row],yhat.astype(np.int32).tolist())), width = 120)\n",
    "pprint(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc61d268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ab846f5850>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(tr_loss_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa65f937",
   "metadata": {},
   "source": [
    "기존의 many2many방식보다 training loss가 빨리 감소하며, 또한 loss가 0이 됨을 볼 수 있었습니다 . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4cd858",
   "metadata": {},
   "source": [
    "# Sequence to Sequence \n",
    "* sequence to sequence 모형을 활용하여 가장 간단한 번역기를 만듭니다. \n",
    "* 가장 대표적인 활용 예시는 번역, 챗봇 등이 있습니다. \n",
    "* sequence2sequence 모형은 입력 문장과 정답 문장을 입력받아 학습을 진행합니다. \n",
    "* Sequence to Sequence 모형은 크게 입력값이 순차적으로 입력되는 Encoder 모듈과, 재귀적으로 출력값을 산출하는 Decoder 모듈로 이루어집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b98b11",
   "metadata": {},
   "source": [
    "![seqmodel.png](https://blog.kakaocdn.net/dn/cByx3E/btqDyNiSnP2/GX8SnhRzTR8zRwTk2KBoJ0/img.png)\n",
    "* 특히, Decoder 모듈은 자신의 이전 출력값을 누적적으로 입력으로 다시 받아 다음 단어를 유추합니다. \n",
    "* 또한 문장의 시작과 끝의 정보를 인식할 수 있도록 \\<시작\\>토큰과 \\<End\\>토큰을 함께 토큰 dict.에 포함하여 모형을 구현합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb1fc8",
   "metadata": {},
   "source": [
    "![decoder.png](https://blog.kakaocdn.net/dn/VGRNm/btqDCb3D0Wn/MxXJ3uxfp8WrdSK0e9IdHK/img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c86dc8",
   "metadata": {},
   "source": [
    "## 라이브러리 호출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f78365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pprint import pprint \n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import font_manager, rc \n",
    "\n",
    "rc('font', family='MalgunGothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b696133",
   "metadata": {},
   "source": [
    "## 데이터셋 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6302303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x 데이터 \n",
    "sources = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "\n",
    "# 목적 데이터 \n",
    "targets = [['나는', '배가', '고프다'],\n",
    "           ['텐서플로우는', '매우', '어렵다'],\n",
    "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
    "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5ddfab",
   "metadata": {},
   "source": [
    "## 데이터 전처리 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c597e0c",
   "metadata": {},
   "source": [
    "### source의 토큰 dictionary 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e7177a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'I': 1, 'a': 2, 'changing': 3, 'deep': 4, 'difficult': 5, 'fast': 6, 'feel': 7, 'for': 8, 'framework': 9, 'hungry': 10, 'is': 11, 'learning': 12, 'tensorflow': 13, 'very': 14}\n"
     ]
    }
   ],
   "source": [
    "s_vocab = list(set(sum(sources, [])))\n",
    "s_vocab.sort()\n",
    "\n",
    "s_vocab = [\"<pad>\"] + s_vocab\n",
    "\n",
    "source2idx =  {word : idx for idx, word in enumerate(s_vocab)}\n",
    "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
    "\n",
    "print(source2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34226d85",
   "metadata": {},
   "source": [
    "### target에 대한 token dict 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c93e87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '<bos>': 1, '<eos>': 2, '고프다': 3, '나는': 4, '딥러닝을': 5, '매우': 6, '배가': 7, '변화한다': 8, '빠르게': 9, '어렵다': 10, '위한': 11, '텐서플로우는': 12, '프레임워크이다': 13}\n"
     ]
    }
   ],
   "source": [
    "t_vocab = list(set(sum(targets, [])))\n",
    "t_vocab.sort()\n",
    "\n",
    "# decoder에 입력되는 데이터인 target은 문장의 시작과 끝을 구분할 특별한 토큰이 필요합니다. \n",
    "t_vocab = [\"<pad>\",\"<bos>\", \"<eos>\"] + t_vocab \n",
    "# begining of sentence / end of sentence \n",
    "\n",
    "target2idx = {word:idx for idx,word in enumerate(t_vocab)}\n",
    "idx2target = {idx:word for idx, word in enumerate(t_vocab)}\n",
    "\n",
    "print(target2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1d4b66",
   "metadata": {},
   "source": [
    "### 데이터 인덱싱 함수 구현\n",
    "* assert _ in [], '안내문장' 구문은 마치 C언어의 switch case구문처럼, 사용자의 입력에 따라 다른 실행을 산출하는 구문입니다. \n",
    "* 밑에서 동일한 함수를 source와 target에 대해 적용하기 위해 사용합니다. \n",
    "* 또, target문자열의 경우 입력과 출력 데이터를 각각 설정합니다. 각각의 문장을 아래의 방식으로 전처리 후 정수 인코딩과 패딩을 진행합니다.  \n",
    "    - 입력 : \\[\\<bos\\>, \"..\", \"..\", \"..\", \\<eos\\>\\] \n",
    "    - 출력 : \\[\"..\", \"..\", \"..\", \\<eos\\>\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "981edc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = list(map(lambda sentence : sentence + ['<eos>'], targets))\n",
    "# test = t_input = list(map(lambda sentence : [target2idx.get(token) for token in sentence], test))\n",
    "\n",
    "# print(test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31af74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
    "    assert mode in ['source', 'target'], 'source와 target 중 원하는 모드를 선택해주세요'\n",
    "    \n",
    "    if mode == 'source':\n",
    "        # 인코더에 들어갈 데이터를 정수 인코딩합니다.\n",
    "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
    "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
    "        s_input = pad_sequences(sequences = s_input, maxlen=max_len, padding='post', truncating='post')\n",
    "        \n",
    "        return s_len, s_input \n",
    "    \n",
    "    elif mode == 'target':\n",
    "        # 디코더의 입력으로 들어갈 target 데이터를 전처리 합니다. \n",
    "        # 입력과 정답의 데이터 두가지 형태를 생성합니다. \n",
    "        t_input = list(map(lambda sentence :['<bos>']+sentence+['<eos>'],sequences))\n",
    "        t_input = list(map(lambda sentence :[dic.get(token)for token in sentence] ,t_input))     \n",
    "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
    "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        # 정답값 데이터를 만들어줍니다. \n",
    "        t_output = list(map(lambda sentence : sentence+['<eos>'], sequences))\n",
    "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
    "        t_output = pad_sequences(sequences=t_output, maxlen=max_len, padding='post', truncating='post')\n",
    "        \n",
    "        return t_len, t_input, t_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971663c0",
   "metadata": {},
   "source": [
    "이제 생성한 함수를 이용해 전처리를 진행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b119e823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for source\n",
    "s_max_len = 10\n",
    "s_len, s_input = preprocess(sequences = sources,\n",
    "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
    "print(s_len, s_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d5f6893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 6, 6] [[ 1  4  7  3  2  0  0  0  0  0  0  0]\n",
      " [ 1 12  6 10  2  0  0  0  0  0  0  0]\n",
      " [ 1 12  5 11 13  2  0  0  0  0  0  0]\n",
      " [ 1 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
      " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
      " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
      " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for target\n",
    "t_max_len = 12\n",
    "t_len, t_input, t_output = preprocess(sequences = targets,\n",
    "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
    "print(t_len, t_input, t_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fffe3d",
   "metadata": {},
   "source": [
    "## Hyper-parameter 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85a57305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "epochs = 200\n",
    "batch_size = 4\n",
    "learning_rate = .005\n",
    "total_step = epochs / batch_size\n",
    "buffer_size = 100\n",
    "n_batch = buffer_size//batch_size\n",
    "embedding_dim = 32\n",
    "units = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aa2eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input데이터 파이프라이닝 \n",
    "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
    "data = data.shuffle(buffer_size = buffer_size)\n",
    "data = data.batch(batch_size = batch_size)\n",
    "# s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18390ea6",
   "metadata": {},
   "source": [
    "## 모형 유닛 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0b17e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "    return tf.keras.layers.GRU(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_initializer='glorot_uniform')\n",
    "# xiavier initalization을 이용해 모형에 들어가는 모든 가중치를 초기화해 성능을 높입니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1377069",
   "metadata": {},
   "source": [
    "##### 인코더 구조를 생성하는 class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7b7d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_units = encoder_units \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.encoder_units)\n",
    "    # 모델 연결 \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        \n",
    "        return output, state \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoder_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9268c1ee",
   "metadata": {},
   "source": [
    "##### 디코더를 생성하는 class \n",
    "* 임베딩층을 타오 들어온 값이 순차적으로 gru를 통과한 후, FC layer의 입력에 맞게 펼쳐져 분류가 수행되는 모형입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ef51235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoder_units = decoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.decoder_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "                \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64263b2",
   "metadata": {},
   "source": [
    "##### 모형의 각 개체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4c0ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
    "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73a5e6",
   "metadata": {},
   "source": [
    "## 비용함수 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73bcdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ea0a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - np.equal(real, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb3a54",
   "metadata": {},
   "source": [
    "## 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d29ed8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baa51706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = './data_out/training_checkpoints'\n",
    "# checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "# checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "#                                 encoder=encoder,\n",
    "#                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81632495",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "282eb2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.0397 Batch Loss 0.9924\n",
      "Epoch 10 Loss 0.0387 Batch Loss 0.9668\n",
      "Epoch 20 Loss 0.0372 Batch Loss 0.9311\n",
      "Epoch 30 Loss 0.0347 Batch Loss 0.8663\n",
      "Epoch 40 Loss 0.0302 Batch Loss 0.7559\n",
      "Epoch 50 Loss 0.0271 Batch Loss 0.6780\n",
      "Epoch 60 Loss 0.0242 Batch Loss 0.6043\n",
      "Epoch 70 Loss 0.0216 Batch Loss 0.5394\n",
      "Epoch 80 Loss 0.0191 Batch Loss 0.4772\n",
      "Epoch 90 Loss 0.0167 Batch Loss 0.4175\n",
      "Epoch 100 Loss 0.0144 Batch Loss 0.3602\n",
      "Epoch 110 Loss 0.0122 Batch Loss 0.3058\n",
      "Epoch 120 Loss 0.0103 Batch Loss 0.2563\n",
      "Epoch 130 Loss 0.0085 Batch Loss 0.2134\n",
      "Epoch 140 Loss 0.0071 Batch Loss 0.1780\n",
      "Epoch 150 Loss 0.0060 Batch Loss 0.1506\n",
      "Epoch 160 Loss 0.0052 Batch Loss 0.1304\n",
      "Epoch 170 Loss 0.0047 Batch Loss 0.1163\n",
      "Epoch 180 Loss 0.0043 Batch Loss 0.1065\n",
      "Epoch 190 Loss 0.0040 Batch Loss 0.0995\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
    "\n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([target2idx['<bos>']] * batch_size, 1)\n",
    "            \n",
    "            #Teacher Forcing: feeding the target as the next input\n",
    "            for t in range(1, t_input.shape[1]):\n",
    "                \n",
    "                predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(t_input[:, t], predictions)\n",
    "            \n",
    "                dec_input = tf.expand_dims(t_input[:, t], 1) #using teacher forcing\n",
    "                \n",
    "        batch_loss = (loss / int(t_input.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradient = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradient, variables))\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        #save model every 10 epoch\n",
    "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch,\n",
    "                                            total_loss / n_batch,\n",
    "                                            batch_loss.numpy()))\n",
    "#         checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca803af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=int32, numpy=\n",
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.expand_dims([target2idx['<bos>']] * batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b80bf",
   "metadata": {},
   "source": [
    "##### Teaching Force \n",
    "![TeachingForce.png](https://miro.medium.com/max/842/1*U3d8D_GnfW13Y3nDgvwJSw.png)\n",
    "* Teaching Force란 디코더의 예측성능 향상을 위해 모형의 각 상태의 입력에 이전 상태의 출력을 넣어주는것이 아니라, 실제 정답값을 직접 넣어주는 방식을 의미합니다. \n",
    "* 만약, 이러한 과정이 없다면, 첫 예측의 결과가 틀렸을때, 전체 문장의 정답이 달라지기 때문에 이를 방지하기 위해 이전 상태의 정답이 틀려도 실제 값을 넣어줌으로써 학습을 이어 진행하는 방식입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0225c64d",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a6b04af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore checkpoint\n",
    "\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88541196",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I feel hungry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0e91f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel hungry\n",
      "나는 배가 고프다 <eos> \n"
     ]
    }
   ],
   "source": [
    "def prediction(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    \n",
    "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "        \n",
    "    result = ''\n",
    "    \n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "        \n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang['<bos>']], 0)\n",
    "    \n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += idx2target[predicted_id] + ' '\n",
    "\n",
    "        if idx2target.get(predicted_id) == '<eos>':\n",
    "            return result, sentence\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)    \n",
    "    \n",
    "    return result, sentence\n",
    "    \n",
    "result, output_sentence = prediction(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)\n",
    "\n",
    "print(sentence)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b002948",
   "metadata": {},
   "source": [
    "모형의 구조가 상당부분 복잡해 복습이 필요합니다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc213825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
