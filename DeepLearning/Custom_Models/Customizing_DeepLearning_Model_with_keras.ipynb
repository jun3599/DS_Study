{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6b9324",
   "metadata": {},
   "source": [
    "# Customizing Model \n",
    "* 이 노트북은 딥러닝 모형을 커스텀 하기 위한 학습을 진행하기 위해 생성되었습니다. \n",
    "* 특히, 해당 노트북은 커스텀하게 구조화된 모형을 학습 시키기 위한 방법을 고안하기 위해 만들어졌으며\n",
    "* 주로 keras.fit() 메소드를 low Level에서 개인화 하기 위한 학습을 진행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c481f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347a8f4",
   "metadata": {},
   "source": [
    "## customize Keras.fit( ) 공식문서 공부하기\n",
    "* 해당 파트는 [Keras 공식문서 || Customizing what happens in fit()](https://keras.io/guides/customizing_what_happens_in_fit/)의 내용을 기반으로 작성하였습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441770c9",
   "metadata": {},
   "source": [
    "* 커스텀 모형을 학습시키는 방식에는 크게 tf.GradientTape메소드와 반복문의 조합을 통한 방식과  \n",
    "* keras의 fit 메소드를 사용하는 두가지 방식이 존재합니다. \n",
    "  \n",
    "* GradientTape을 사용한다면 모형의 세부사항까지 통제가 가능하다는 장점을 갖지만, callback과 built-in distribution support, step fusing과 같은 편리한 기능의 이점을 활용하려면 fit 메소드를 응용할 수 있는 능력이 요구됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9fc94b",
   "metadata": {},
   "source": [
    "* fit( ) 메소드를 커스텀 하기 위해서는 Model class의 training step function을 Override하면 된다고 합니다. \n",
    "* 해당 부분은 fit( ) 메소드에 의해 매번 배치시 마다 호출되는 함수입니다.  \n",
    "    (아래의 예시에서는 subclassing예제를 보여주지만, functional api, sequential Model subclassed model 어디에서든 사용가능합니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32be26a",
   "metadata": {},
   "source": [
    "### first example\n",
    "* keras.Model을 subclassing하는 새로운 모형을 생성합니다. \n",
    "* 이때, 단순히 **train_step(self,data)** 부분을 오버라이딩 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # 데이터를 unpack합니다. 해당 부분의 형태는 \n",
    "        # fit()을 통해 모형의 입력으로 사용된 데이터의 형태에 따라 달라집니다. \n",
    "        # fit(x,y,...)형태의 입력을 가정합니다. \n",
    "        x,y = data \n",
    "        \n",
    "        # loss를 계산합니다. \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training = True) # 순전파를 통한 예측 \n",
    "            # loss값을 계산합니다. \n",
    "            # loss함수는 compile()을 통해 입력된 loss함수를 기준으로 합니다. \n",
    "            loss = self.compiled_loss(y,y_pred, regularization_losses = self.losses)\n",
    "        \n",
    "        # 기울기를 계산합니다. \n",
    "        # 대상 노드 정보를 담습니다. \n",
    "        trainable_vars = self.trainable_variables \n",
    "        # 각각의 기울기를 구해줍니다. \n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # 구한 기울기를 경사하강법을 적용해 각각의 간선에 반영해줍니다. \n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # metrics를 업데이트합니다. (이때, loss를 추적하는 metrics도 같이 업데이트해줍니다.)\n",
    "        self.compiled_metrics.update_state(y,y_pred)\n",
    "        \n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aff3122",
   "metadata": {},
   "source": [
    "##### 상세설명\n",
    "1. **data** : fit()메소드에 입력되는 데이터를 의미합니다. \n",
    "    - 만약 fit(x,y, ...)을 입력으로 사용했다면 data는 (x,y)의 튜플이 될 것입니다. \n",
    "    - 만약 tf.keras.Dataset으로 생성한 dataset을 입력으로 fit(dataset, ...)을 사용했다면 data에는 각각의 배치에서 dataset에 의해 산출되는 형태가 될 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274cefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 모형을 사용해봅니다. \n",
    "import numpy as np \n",
    "\n",
    "# 위에서 subclassing을 진행한 customModel의 인스턴스를 생성합니다. \n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "# 이 부분에서 모형을 사용합니다. \n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# fit은 평소 사용하던데로 진행합니다. \n",
    "x = np.random.random((1000,32))\n",
    "y = np.random.random((1000,1))\n",
    "model.fit(x,y, epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4694c0c",
   "metadata": {},
   "source": [
    "### Going lower-level \n",
    "* 기본적으로는 compile()메소드에 어떠한 인자를 입력하지 않고, 기본적으로 모든 인자를 train_step에 있는 기본 값으로 설정할 수도 있습니다. \n",
    "* 아래의 예시는 단순히 compile()메소드를 옵티마이져를 구성하기 위해서만 사용하는 경우를 상정한 모델링 방식을 예시로 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a4a18",
   "metadata": {},
   "source": [
    "1. loss를 추적하고 MAE 스코어를 추적하기 위한 Metric 인스턴스를 생성합니다. \n",
    "2. train_step과정에서 .update_state() 메소드를 사용해 해당 값들을 갱신해주고 .result()메소드를 통해 학습 과정중에서 해당 값들의 최신 값을 조회하고 이를 진행상태 bar에 표시해줌과 동시에 callback에 사용될 수 있도록 해줍니다. \n",
    "3. 주의사항은 각각의 에포크 사이에 필수적으로 reset_state를 통해 값을 초기화 시켜주어야 한다는 점입니다. (그렇지 않으면 result()가 뱉어내는 값은 처음 학습을 시작할때부터 지금까지의 평균치를 뱉어낼 것입니다.) \n",
    "*  Thankfully, the framework can do that for us: just list any metric you want to reset in the **metrics property** of the model. The model will call reset_states() on any object listed here at the beginning of each fit() epoch or at the beginning of a call to evaluate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용하고자하는 각각의 metrics를 class밖의 전역변수로 선언하고, class에 넘겨줍니다. \n",
    "# 이전에는 self.metrics를 통해 compile시 들어온 metric을 사용했지만, 이번에는 직접 입력하고 컴파일 옵션에는 별도로 지정하지 않습니다. \n",
    "loss_tracker = keras.metrics.Mean(name='loss')\n",
    "mae_metric = keras.metrics.MeanAbsoluteError(name='mae')\n",
    "\n",
    "# 서브클레싱을 진행합니다. 이때, metric을 전역변수에 선언된 내용을 기반으로 진행합니다. \n",
    "class CustomModel(keras.Model):\n",
    "    \n",
    "    # 해당 부분은 fit 메소드가 한번의 에포크마다 사용하는 부분입니다. \n",
    "    def train_step(self,data):\n",
    "        # 입력된 데이터의 형태에 따라 unpack을 진행합니다. \n",
    "        x,y = data \n",
    "        \n",
    "        # loss를 계산합니다.(1번의 에포크 안에서 여러번 계산(한번의 전파시 한번의 갱신)) \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True) # 순전파 \n",
    "            # loss를 계산합니다. \n",
    "            loss = keras.losses.mean_squared_error(y,y_pred)\n",
    "        \n",
    "        # 기울기를 계산합니다. \n",
    "        trainable_vars = self.trainable_variables \n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        \n",
    "        # 가중치를 업데이트합니다. \n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        # 직접 생성한 메트릭스를 계산합니다. \n",
    "        # 한번의 에포크 안에서 발생한 여러번의 연산 결과를 누적 평균 및 누적 mae 를 진행 \n",
    "        # 한번의 에포크가 끝나면 return 후 reset_state()\n",
    "        loss_tracker.update_state(loss)\n",
    "        mae_metric.update_state(y,y_pred)\n",
    "        \n",
    "        return {\"loss\":loss_tracker.result(), \"mae\":mae_metric.result()}\n",
    "    \n",
    "    @property \n",
    "    def metrics(self):\n",
    "        # 해당부분에 우리가 정의한 'metric'들의 list를 두면 \n",
    "        # 모델이 자동적으로 각각의 에포크 사이에 reset_state()를 진행해줍니다. \n",
    "        return [loss_tracker, mae_metric]\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fa00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom model의 인스턴스를 생성합니다. \n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "# 모형에 메트릭스를 정의하지 않습니다. \n",
    "model.compile(optimizer=\"adam\")\n",
    "\n",
    "x= np.random.random((100000,32))\n",
    "y = np.random.random((100000,1))\n",
    "model.fit(x,y, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37286e",
   "metadata": {},
   "source": [
    "### Supporting sample_weight & class_weight\n",
    "You may have noticed that our first basic example didn't make any mention of sample weighting. If you want to support the fit() arguments sample_weight and class_weight, you'd simply do the following:\n",
    "  \n",
    "  \n",
    "* Unpack sample_weight from the data argument\n",
    "* Pass it to compiled_loss & compiled_metrics (of course, you could also just apply it manually if you don't rely on compile() for losses & metrics)\n",
    "* That's it. That's the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        if len(data) == 3:\n",
    "            x, y, sample_weight = data\n",
    "        else:\n",
    "            sample_weight = None\n",
    "            x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value.\n",
    "            # The loss function is configured in `compile()`.\n",
    "            loss = self.compiled_loss(\n",
    "                y,\n",
    "                y_pred,\n",
    "                sample_weight=sample_weight,\n",
    "                regularization_losses=self.losses,\n",
    "            )\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics.\n",
    "        # Metrics are configured in `compile()`.\n",
    "        self.compiled_metrics.update_state(y, y_pred, sample_weight=sample_weight)\n",
    "\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "# Construct and compile an instance of CustomModel\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# You can now use sample_weight argument\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "sw = np.random.random((1000, 1))\n",
    "model.fit(x, y, sample_weight=sw, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4557d7",
   "metadata": {},
   "source": [
    "* 해당 부분은 추후 복습을 진행할 예정입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160e3d6",
   "metadata": {},
   "source": [
    "### Providing your own evaluation step\n",
    "What if you want to do the same for calls to model.evaluate()? Then you would override test_step in exactly the same way. Here's what it looks like:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e373f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        # Compute predictions\n",
    "        y_pred = self(x, training=False)\n",
    "        # Updates the metrics tracking the loss\n",
    "        self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "# Construct an instance of CustomModel\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Evaluate with our custom test_step\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.evaluate(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d400a4c",
   "metadata": {},
   "source": [
    "* 해당 부분 및 GAN예제 또한 추후 보강 예정입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc9fdba",
   "metadata": {},
   "source": [
    "## Make Customized Model\n",
    "* 학습을 위한 테스트 모형을 구성합니다. \n",
    "* 모형의 구조는 2SLS 계량 모형을 구조화 하여 신경망으로 만든 테스트 모델입니다. \n",
    "[main](https://frhyme.github.io/machine-learning/a_model_in_keras/)  [sub1](https://machinelearningmastery.com/deep-learning-models-for-multi-output-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936c3b9",
   "metadata": {},
   "source": [
    "### 방법1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6707f41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           384         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           2080        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            33          dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            20          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5)            0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           384         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            33          dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,014\n",
      "Trainable params: 5,014\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model():\n",
    "    \n",
    "    # first stage \n",
    "    input1 = tf.keras.layers.Input(shape= (5,))\n",
    "    x = tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu)(input1)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu)(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(1)(x)\n",
    "    x = keras.Model(inputs= input1, outputs= x)\n",
    "    \n",
    "    # second stage  \n",
    "    input2 = tf.keras.Input(shape= (4,))\n",
    "    y = tf.keras.layers.Dense(4)(input2)\n",
    "    y = keras.Model(inputs= input2, outputs=y) \n",
    "    \n",
    "    concat = tf.keras.layers.concatenate([x.output, y.output])\n",
    "    \n",
    "    z = tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu)(concat)\n",
    "    z = tf.keras.layers.Dropout(0.4)(z)\n",
    "    z = tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu)(z)\n",
    "    z = tf.keras.layers.Dropout(0.4)(z)\n",
    "    z = tf.keras.layers.Dense(1)(z)\n",
    "    \n",
    "    model = keras.Model(inputs= [x.input, y.input], outputs=z)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "model = model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef09b0a",
   "metadata": {},
   "source": [
    "* 해당 방식은 전체 학습과정을 완료한 이후, 최종적인 ouput과 실제 output만을 비교하여 학습한다는 단점을 지닙니다. \n",
    "* 2SLS모형 처럼 first stage에서도 실제값과 예측값의 차이를 활용한 가중치 업데이트가 가능하도록 모형을 설계해야 합니다. \n",
    "\n",
    "* 또한, 모형은 생성하였으나 이를 학습시키기 위한 방안에 대해 고민해보아야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2ad8f",
   "metadata": {},
   "source": [
    "### 방법2 - Keras의 Multi-input Multi-output 모형 구조 응용하기\n",
    "* 해당 방식은 keras의 공식 문서를 인용한 블로그의 내용을 참조하여 구성하였습니다. [keras의 model을 파봅시다](https://frhyme.github.io/machine-learning/a_model_in_keras/)[Keras Multi(input, output)모델 생성 방법](https://deeptak.tistory.com/7)\n",
    "* 여러개의 input과 output을 갖는 모형을 구조화 합니다. \n",
    "* 해당 방식은 당초 원하던, 도구 변수를 통한 예측값의 도출과. 실제값과의 비교를 통한 가중치 수정 방식을 갖는다는 점에서 의의를 갖습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa988d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_input (InputLayer)        [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           320         first_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           2080        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "second_input (InputLayer)       [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6)            0           second_input[0][0]               \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           448         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            33          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,027\n",
      "Trainable params: 5,027\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# first stage input layer \n",
    "first_input = keras.layers.Input(shape=(4,), name='first_input')\n",
    "stage1 = keras.layers.Dense(64, activation=tf.nn.leaky_relu)(first_input)\n",
    "stage1 = keras.layers.Dropout(0.4)(stage1)\n",
    "stage1 = keras.layers.Dense(32, activation=tf.nn.leaky_relu)(stage1)\n",
    "stage1 = keras.layers.Dropout(0.4)(stage1)\n",
    "\n",
    "# stage1의 중간 출력 노드 \n",
    "auxiliary_output = keras.layers.Dense(1, activation='linear', name='aux_output')(stage1)\n",
    "\n",
    "# stage1에서 다음 스테이지로 넘어갈 output \n",
    "stage1_out = keras.layers.Dense(1)(stage1)\n",
    "    \n",
    "# second stage input layer \n",
    "second_input = keras.layers.Input(shape=(5,), name='second_input')\n",
    "\n",
    "# concat 이후 main stream으로 \n",
    "x = keras.layers.concatenate([second_input, stage1_out])\n",
    "\n",
    "x = tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu)(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu)(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "main_output = tf.keras.layers.Dense(1, activation='linear', name='main_output')(x)\n",
    "\n",
    "# 전체 모형 생성 \n",
    "model = keras.Model(inputs=[first_input, second_input], outputs=[main_output,auxiliary_output])\n",
    "\n",
    "# 모델 컴파일 \n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "139c982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "first = np.random.random((1000,4))\n",
    "second = np.random.random((1000,5))\n",
    "\n",
    "z = np.random.random((1000,1))\n",
    "y = np.random.random((1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad830d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 0.8123 - main_output_loss: 0.3655 - aux_output_loss: 0.4468\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5995 - main_output_loss: 0.2978 - aux_output_loss: 0.3016\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5602 - main_output_loss: 0.2836 - aux_output_loss: 0.2766\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5526 - main_output_loss: 0.2802 - aux_output_loss: 0.2725\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5540 - main_output_loss: 0.2721 - aux_output_loss: 0.2819\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5345 - main_output_loss: 0.2667 - aux_output_loss: 0.2678\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5352 - main_output_loss: 0.2660 - aux_output_loss: 0.2693\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5276 - main_output_loss: 0.2593 - aux_output_loss: 0.2682\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5256 - main_output_loss: 0.2617 - aux_output_loss: 0.2639\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5285 - main_output_loss: 0.2615 - aux_output_loss: 0.2671\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5241 - main_output_loss: 0.2623 - aux_output_loss: 0.2618\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5168 - main_output_loss: 0.2567 - aux_output_loss: 0.2600\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5168 - main_output_loss: 0.2577 - aux_output_loss: 0.2591\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5191 - main_output_loss: 0.2585 - aux_output_loss: 0.2605\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5165 - main_output_loss: 0.2587 - aux_output_loss: 0.2578\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5128 - main_output_loss: 0.2520 - aux_output_loss: 0.2609: 0s - loss: 0.5128 - main_output_loss: 0.2520 - aux_output_loss: 0.26\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5182 - main_output_loss: 0.2594 - aux_output_loss: 0.2588\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5095 - main_output_loss: 0.2543 - aux_output_loss: 0.2552\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5136 - main_output_loss: 0.2567 - aux_output_loss: 0.2570\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5072 - main_output_loss: 0.2505 - aux_output_loss: 0.2566\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5123 - main_output_loss: 0.2576 - aux_output_loss: 0.2547\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5169 - main_output_loss: 0.2568 - aux_output_loss: 0.2601\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5103 - main_output_loss: 0.2530 - aux_output_loss: 0.2573\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5034 - main_output_loss: 0.2501 - aux_output_loss: 0.2533\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5061 - main_output_loss: 0.2474 - aux_output_loss: 0.2587\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5087 - main_output_loss: 0.2540 - aux_output_loss: 0.2547\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5005 - main_output_loss: 0.2468 - aux_output_loss: 0.2536\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5073 - main_output_loss: 0.2528 - aux_output_loss: 0.2545\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5073 - main_output_loss: 0.2523 - aux_output_loss: 0.2549\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5094 - main_output_loss: 0.2535 - aux_output_loss: 0.2559\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5028 - main_output_loss: 0.2511 - aux_output_loss: 0.2517\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4990 - main_output_loss: 0.2468 - aux_output_loss: 0.2522\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5062 - main_output_loss: 0.2515 - aux_output_loss: 0.2547\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5046 - main_output_loss: 0.2508 - aux_output_loss: 0.2537\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5039 - main_output_loss: 0.2512 - aux_output_loss: 0.2527\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.4957 - main_output_loss: 0.2473 - aux_output_loss: 0.2484\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5038 - main_output_loss: 0.2521 - aux_output_loss: 0.2516\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5031 - main_output_loss: 0.2493 - aux_output_loss: 0.2537\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5068 - main_output_loss: 0.2543 - aux_output_loss: 0.2526\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5039 - main_output_loss: 0.2504 - aux_output_loss: 0.2535\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5024 - main_output_loss: 0.2508 - aux_output_loss: 0.2515\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5025 - main_output_loss: 0.2499 - aux_output_loss: 0.2525\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5042 - main_output_loss: 0.2503 - aux_output_loss: 0.2539\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5003 - main_output_loss: 0.2491 - aux_output_loss: 0.2512\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5019 - main_output_loss: 0.2520 - aux_output_loss: 0.2498\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5056 - main_output_loss: 0.2520 - aux_output_loss: 0.2536\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5004 - main_output_loss: 0.2496 - aux_output_loss: 0.2508\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5029 - main_output_loss: 0.2506 - aux_output_loss: 0.2524\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4972 - main_output_loss: 0.2486 - aux_output_loss: 0.2486\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5028 - main_output_loss: 0.2506 - aux_output_loss: 0.2522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2125b2bbee0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({'first_input': first, 'second_input': second}, \n",
    "          {'main_output': y, 'aux_output': z}, \n",
    "          epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e01ec1",
   "metadata": {},
   "source": [
    "* 하지만, 학습과정에서 일어나는 현상에 대해서는 아직 공부가 더 필요합니다. \n",
    "* 만약 학습 방식이 모든 stage를 마치고 가중치를 업데이트하는 방식이라면, 당초 예상하던 학습 형태와는 거리가 있다고 생각합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a16c92",
   "metadata": {},
   "source": [
    "## 앞단의 모형을 먼저 학습시키고, 연결하는 방식은 어떨까? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e544f6",
   "metadata": {},
   "source": [
    "[stackoverflow | How to concatnate two pretrained models](https://stackoverflow.com/questions/66852496/how-to-concatenate-two-pre-trained-models-in-keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b461e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d65ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5364f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f35f0ce",
   "metadata": {},
   "source": [
    "## 한번의 트레이닝에서 모형 전체를 학습시킬 순 없을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2f3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
